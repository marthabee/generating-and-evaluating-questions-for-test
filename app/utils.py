from typing import List, Optional
from pydantic import BaseModel
from sqlalchemy.orm import Session
import re
from .models import Job, JobTest, TestQuestion, QuestionAnswer, TestResult, Application
import os
import requests
from langdetect import detect
import json
from datetime import datetime

LLM_API_URL = os.getenv("LLM_API_URL", "https://api.groq.com/openai/v1/chat/completions")
LLM_MODEL_NAME = os.getenv("LLM_MODEL_NAME", "llama3-8b-8192")
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")

# --------- Pydantic Schemas ---------
class GenerateQuestionRequest(BaseModel):
    job_id: int

class QuestionCreate(BaseModel):
    test_id: int
    question_text: str
    explanation: str = ""

class EvaluateAnswerRequest(BaseModel):
    question_id: int
    result_id: int

# --------- Language Detection ---------
def detect_language(text: str) -> str:
    try:
        lang = detect(text)
        return 'vi' if lang == 'vi' else 'en'
    except:
        return 'en'

# --------- Prompt Builder ---------
def get_prompt(jd: str, lang: str) -> str:
    if lang == 'vi':
        return f"""
            Báº¡n lÃ  chuyÃªn gia tuyá»ƒn dá»¥ng. DÆ°á»›i Ä‘Ã¢y lÃ  mÃ´ táº£ cÃ´ng viá»‡c:
            \"\"\"{jd}\"\"\"

            **Nhiá»‡m vá»¥**:
            1. XÃ¡c Ä‘á»‹nh má»©c Ä‘á»™ kinh nghiá»‡m yÃªu cáº§u cho vá»‹ trÃ­ nÃ y (Ã­t kinh nghiá»‡m, trung bÃ¬nh, hoáº·c cao cáº¥p) dá»±a trÃªn ná»™i dung JD.
            2. Dá»±a vÃ o má»©c Ä‘á»™ Ä‘Ã³, táº¡o 5 cÃ¢u há»i phá»ng váº¥n chuyÃªn sÃ¢u vÃ  phÃ¹ há»£p **báº±ng TIáº¾NG VIá»†T**, Ä‘á»ƒ Ä‘Ã¡nh giÃ¡:
               - Ká»¹ nÄƒng chuyÃªn mÃ´n chÃ­nh - **3 cÃ¢u**.
               - Kháº£ nÄƒng giáº£i quyáº¿t váº¥n Ä‘á» hoáº·c xá»­ lÃ½ tÃ¬nh huá»‘ng thá»±c táº¿ - **1 cÃ¢u**.
               - Sá»± phÃ¹ há»£p vá»›i vai trÃ² vÃ  tá»• chá»©c - **1 cÃ¢u**.

            **Äá»‹nh nghÄ©a má»©c Ä‘á»™ kinh nghiá»‡m**:
            - **Ãt kinh nghiá»‡m (Entry-level, dÆ°á»›i 2 nÄƒm)**:
              - á»¨ng viÃªn má»›i ra trÆ°á»ng hoáº·c cÃ³ Ã­t kinh nghiá»‡m.
              - NÃªn há»i vá»: kiáº¿n thá»©c ná»n táº£ng, cÃ´ng cá»¥ cÆ¡ báº£n, quy trÃ¬nh Ä‘Æ¡n giáº£n, hiá»ƒu biáº¿t lÃ½ thuyáº¿t.
            - **Kinh nghiá»‡m trung bÃ¬nh (2â€“5 nÄƒm)**:
              - ÄÃ£ lÃ m viá»‡c thá»±c táº¿, cÃ³ kháº£ nÄƒng giáº£i quyáº¿t váº¥n Ä‘á» Ä‘á»™c láº­p.
              - NÃªn há»i vá»: kinh nghiá»‡m triá»ƒn khai, phÃ¢n tÃ­ch tÃ¬nh huá»‘ng thá»±c táº¿, cáº£i tiáº¿n cÃ´ng viá»‡c.
            - **Kinh nghiá»‡m cao (Senior, trÃªn 5 nÄƒm)**:
              - CÃ³ kháº£ nÄƒng ra quyáº¿t Ä‘á»‹nh, tá»‘i Æ°u há»‡ thá»‘ng, hoáº·c lÃ£nh Ä‘áº¡o nhÃ³m.
              - NÃªn há»i vá»: chiáº¿n lÆ°á»£c, táº§m nhÃ¬n há»‡ thá»‘ng, kinh nghiá»‡m quáº£n lÃ½ hoáº·c mentoring.

            **YÃªu cáº§u**:
            - Má»—i cÃ¢u há»i pháº£i rÃµ rÃ ng, trÃ¡nh chung chung.
            - Tráº£ lá»i hoÃ n toÃ n báº±ng **tiáº¿ng Viá»‡t**, tráº£ vá» 1 danh sÃ¡ch cÃ¢u há»i khÃ´ng cáº§n dá»‹ch hay giáº£i thÃ­ch gÃ¬ thÃªm.
        """
    else:
        return f"""
            You are a professional recruiter. Carefully read the following job description:
            \"\"\"{jd}\"\"\"

            **Your task**:
            1. Determine the required experience level (entry-level, mid-level, or senior-level) based on the JD.
            2. Generate **5 highly relevant interview questions** tailored to that level, aiming to assess:
               - Core technical or functional skills - **3 questions**.
               - Real-world problem solving - **1 question**.
               - Fit for the role and organization - **1 question**.

            **Define the experience levels**:
            - **Entry-level (under 2 years)**:
              - Recent graduates or junior professionals.
              - Ask about: basic concepts, common tools, understanding of workflows, theoretical knowledge.
            - **Mid-level (2â€“5 years)**:
              - Experienced in implementation, troubleshooting, working independently.
              - Ask about: hands-on experience, applied scenarios, improvements they've contributed.
            - **Senior-level (5+ years)**:
              - Decision-makers, system optimizers, team leads.
              - Ask about: strategy, architecture, leadership, mentoring, long-term impact.

            **Guidelines**:
            - Make each question precise and insightful (avoid vague/generic ones).
            - Without explanation or translation or formatting. Only plain list the 5 questions clearly and concisely, based on the job description.
        """

# --------- AI Services ---------

def generate_questions_from_jd(jd_text: str, model: str = LLM_MODEL_NAME) -> List[str]:
    if not jd_text:
        return []

    lang = detect_language(jd_text)
    prompt = get_prompt(jd_text, lang)

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {GROQ_API_KEY}"
    }

    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": "You are a helpful AI assistant."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7
    }

    try:
        response = requests.post(LLM_API_URL, headers=headers, json=payload)
        response.raise_for_status()
        content = response.json().get("choices", [{}])[0].get("message", {}).get("content", "")
        lines = [line.strip("-â€¢ ").strip() for line in content.splitlines() if line.strip()]

        questions = []
        for i, line in enumerate(lines):
            if not line.endswith("?"):
                continue
            question_text = re.sub(r"^\d+\.\s*", "", line).strip()

            if i < 3:
                q_type = "core"
            elif i == 3:
                q_type = "problem_solving"
            else:
                q_type = "fit"

            questions.append({
                "question_text": question_text,
                "question_type": q_type
            })

        return questions

    except Exception as e:
        print("âŒ Error calling Groq API:", e)
        return []
    
# --------- Evaluation Functions ---------

def get_review_prompt(question: str, answer: str, lang: str = LLM_MODEL_NAME) -> str:
    if lang == "vi":
        return f"""
## ğŸ§‘ Vai trÃ² (Role)
Báº¡n lÃ  chuyÃªn gia nhÃ¢n sá»± cáº¥p cao, nhiá»u kinh nghiá»‡m phá»ng váº¥n á»©ng viÃªn.

## ğŸ“„ Bá»‘i cáº£nh (Context)
- CÃ¢u há»i phá»ng váº¥n: {question}
- CÃ¢u tráº£ lá»i cá»§a á»©ng viÃªn: {answer}

## ğŸ“ HÆ°á»›ng dáº«n (Instructions)
1. ÄÃ¡nh giÃ¡ cÃ¢u tráº£ lá»i dá»±a trÃªn má»©c Ä‘á»™ phÃ¹ há»£p vá»›i cÃ¢u há»i, tÃ­nh chÃ­nh xÃ¡c, Ä‘á»™ rÃµ rÃ ng.
2. Viáº¿t **nháº­n xÃ©t ngáº¯n gá»n** (1â€“3 cÃ¢u) giÃºp á»©ng viÃªn hiá»ƒu Ä‘iá»ƒm máº¡nh & Ä‘iá»ƒm yáº¿u.
3. Cháº¥m Ä‘iá»ƒm cÃ¢u tráº£ lá»i trÃªn **thang Ä‘iá»ƒm 100** (0 lÃ  hoÃ n toÃ n sai, 100 lÃ  ráº¥t tá»‘t). náº¿u cÃ¢u tráº£ lá»i trá»‘ng, tráº£ vá» 0. náº¿u cÃ¢u tráº£ lá»i Ä‘Ãºng vá»›i cÃ¢u há»i, tráº£ vá» chÃ­nh xÃ¡c 100.
4. ÄÆ°a ra 1â€“2 gá»£i Ã½ cáº£i thiá»‡n, náº¿u cáº§n.

## ğŸ“¦ Äá»‹nh dáº¡ng (Format)
Tráº£ vá» JSON Ä‘Ãºng cáº¥u trÃºc sau, khÃ´ng giáº£i thÃ­ch thÃªm, khÃ´ng thÃªm thÃ´ng tin khÃ¡c ngoÃ i JSON:

{{
  "score": <sá»‘ nguyÃªn tá»« 0 Ä‘áº¿n 100>,
  "comment": "<nháº­n xÃ©t>",
  "suggestion": "<gá»£i Ã½ cáº£i thiá»‡n náº¿u cÃ³>"
}}

Tráº£ lá»i **hoÃ n toÃ n báº±ng tiáº¿ng Viá»‡t**.
"""
    else:
        return f"""
## ğŸ§‘ Role
You are a senior HR professional with extensive experience interviewing candidates.

## ğŸ“„ Context
- Interview question: {question}
- Candidate's answer: {answer}

## ğŸ“ Instructions
1. Evaluate the answer based on its relevance, accuracy, and clarity.
2. Write a **brief comment** (1â€“3 sentences) summarizing strengths and weaknesses.
3. Give a score from 0 to 100 (0 = completely wrong/no answer, 100 = excellent). if the answer is empty, return 0. if the answer is correct, return exactly 100.
4. Provide 1â€“2 suggestions for improvement, if applicable.

## ğŸ“¦ Format
Return a JSON object matching the exact structure below. Do not include explanations or extra text:

{{
  "score": <integer 0-100>,
  "comment": "<brief feedback>",
  "suggestion": "<improvement advice if any>"
}}

Respond entirely in English.
"""

def generate_evaluation(question: str, answer: str, model: str = LLM_MODEL_NAME) -> dict:
    try:
        lang = detect(answer or question)
    except:
        lang = "vi"

    prompt = get_review_prompt(question, answer, lang)

    response = requests.post(
        "https://api.groq.com/openai/v1/chat/completions",
        headers={
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json",
        },
        json={
            "model": model,
            "messages": [
                {"role": "system", "content": "You are a helpful interview assistant."},
                {"role": "user", "content": prompt},
            ],
            "temperature": 0.3
        }
    )

    if response.status_code != 200:
        print("âŒ Error calling API:", response.text)
        return {}

    content = response.json()["choices"][0]["message"]["content"]

    try:
        return json.loads(content)
    except Exception as e:
        print("âŒ Error parsing JSON:", e)
        print("ğŸ” Content returned:", content)
        return {}

def evaluate_single_answer(question_id: int, answer_id: int, db) -> dict:
    from app.models import TestQuestion, QuestionAnswer

    question = db.query(TestQuestion).filter(TestQuestion.question_id == question_id).first()
    answer = db.query(QuestionAnswer).filter(QuestionAnswer.answer_id == answer_id).first()

    if not question:
        return {"error": "KhÃ´ng tÃ¬m tháº¥y cÃ¢u há»i"}
    if not answer:
        return {"error": "KhÃ´ng tÃ¬m tháº¥y cÃ¢u tráº£ lá»i"}

    if not answer.answer_text:
        return {"error": "CÃ¢u tráº£ lá»i trá»‘ng"}

    eval_result = generate_evaluation(question.question_text, answer.answer_text)

    # TÃ­nh Ä‘iá»ƒm
    score = eval_result.get("score", 0)
    points = float(question.points or 1.0)
    earned = round(score / 100 * points, 2)

    # Cáº­p nháº­t vÃ o DB
    answer.points_earned = earned
    answer.is_correct = score >= 70
    answer.submitted_at = datetime.utcnow()
    db.add(answer)
    db.commit()

    return {
        "answer_id": answer_id,
        "question": question.question_text,
        "answer": answer.answer_text,
        "score": score,
        "earned_points": earned,
        "comment": eval_result.get("comment", ""),
        "suggestion": eval_result.get("suggestion", "")
    }


def evaluate_test_result(result_id: int, db) -> dict:
    result = db.query(TestResult).filter(TestResult.result_id == result_id).first()
    if not result:
        return {"error": "KhÃ´ng tÃ¬m tháº¥y bÃ i lÃ m."}

    answers = db.query(QuestionAnswer).filter(QuestionAnswer.result_id == result_id).all()
    if not answers:
        return {"error": "BÃ i lÃ m khÃ´ng cÃ³ cÃ¢u tráº£ lá»i nÃ o."}

    scores = []
    feedback_list = []

    for ans in answers:
        question = db.query(TestQuestion).filter(TestQuestion.question_id == ans.question_id).first()
        if not question or not ans.answer_text:
            continue

        eval_result = generate_evaluation(question.question_text, ans.answer_text)

        # Cháº¥m Ä‘iá»ƒm
        score = eval_result.get("score", 0)
        points = float(question.points or 1.0)
        earned = round(score / 100 * points, 2)

        ans.points_earned = earned
        ans.is_correct = score >= 70
        ans.submitted_at = datetime.utcnow()
        db.add(ans)

        scores.append(score)  # <-- Cháº¥m theo thang Ä‘iá»ƒm 100, lÆ°u Ä‘á»ƒ tÃ­nh trung bÃ¬nh
        feedback_list.append(f"Q{question.order_index}: {eval_result.get('comment', '')}")

    db.commit()

    # Tá»•ng & trung bÃ¬nh
    total_score = round(sum(scores), 2)
    average_score = round(total_score / len(scores), 2)

    # ÄÃ¡nh giÃ¡ Ä‘áº¡t hay khÃ´ng: trung bÃ¬nh >= 60
    passing_score = 60
    passed = average_score >= passing_score

    # Cáº­p nháº­t test_results
    result.total_score = total_score
    result.percentage = average_score
    result.passed = passed
    result.graded_at = datetime.utcnow()
    result.feedback = "\n".join(feedback_list)
    db.add(result)
    db.commit()

    return {
        "result_id": result_id,
        "total_score": total_score,
        "average_score": average_score,
        "passed": passed,
        "feedback": feedback_list
    }



def get_answer_details(result_id: int, db: Session):
    result = db.query(TestResult).filter(TestResult.result_id == result_id).first()
    if not result:
        return {"error": "KhÃ´ng tÃ¬m tháº¥y bÃ i lÃ m."}

    answers = (
        db.query(QuestionAnswer)
        .filter(QuestionAnswer.result_id == result_id)
        .order_by(QuestionAnswer.answer_id)
        .all()
    )

    if not answers:
        return {"error": "KhÃ´ng cÃ³ cÃ¢u tráº£ lá»i nÃ o."}

    details = []
    for answer in answers:
        question = db.query(TestQuestion).filter(TestQuestion.question_id == answer.question_id).first()
        details.append({
            "question_id": question.question_id,
            "question_text": question.question_text,
            "answer_id": answer.answer_id,
            "answer_text": answer.answer_text,
            "score": answer.points_earned,
            "is_correct": answer.is_correct,
            "submitted_at": answer.submitted_at,
            "comment": getattr(answer, "comment", ""),        
            "suggestion": getattr(answer, "suggestion", "")   
        })

    return {
        "result_id": result_id,
        "test_id": result.test_id,
        "questions_and_answers": details
    }


# --------- CRUD helpers ---------
def get_job(db: Session, job_id: int) -> Optional[Job]:
    return db.query(Job).filter(Job.job_id == job_id).first()

def get_or_create_job_test(db: Session, job_id: int) -> JobTest:
    test = db.query(JobTest).filter(JobTest.job_id == job_id).first()
    if test:
        return test
    test = JobTest(job_id=job_id, test_name="Auto Generated Test")
    db.add(test); db.commit(); db.refresh(test)
    return test

def create_question(db: Session, test_id: int, question_text: str, explanation: str = "") -> TestQuestion:
    q = TestQuestion(test_id=test_id, question_text=question_text, explanation=explanation)
    db.add(q); db.commit(); db.refresh(q)
    return q

def latest_answer_for_question(db: Session, question_id: int) -> Optional[QuestionAnswer]:
    return (db.query(QuestionAnswer)
              .filter(QuestionAnswer.question_id == question_id)
              .order_by(QuestionAnswer.answer_id.desc())
              .first())

def get_answer_by_result_question(db: Session, result_id: int, question_id: int) -> Optional[QuestionAnswer]:
    return db.query(QuestionAnswer).filter(QuestionAnswer.result_id == result_id, QuestionAnswer.question_id == question_id).first()

def get_answer_by_id(db: Session, answer_id: int) -> Optional[QuestionAnswer]:
    return db.query(QuestionAnswer).filter(QuestionAnswer.answer_id == answer_id).first()

